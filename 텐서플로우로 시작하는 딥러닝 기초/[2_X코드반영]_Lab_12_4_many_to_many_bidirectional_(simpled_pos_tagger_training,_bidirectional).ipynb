{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC__DAZu6xqs"
      },
      "source": [
        "# Lab 12-4 many to many variable bidirectional\n",
        "### simple pos-tagger training \n",
        "* many to many\n",
        "* variable input sequence length\n",
        "* bi-directional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caAHPexJ6xq9",
        "outputId": "22d52539-fa6c-4abc-aa1f-f77c9512d515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjJm22oW6xrE"
      },
      "source": [
        "### Prepairing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LJcWWWxy6xrG"
      },
      "outputs": [],
      "source": [
        "# example data\n",
        "sentences = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "pos = [['pronoun', 'verb', 'adjective'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective'],\n",
        "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RH7b8AI6xrH"
      },
      "source": [
        "### Preprocessing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImoMe3026xrJ",
        "outputId": "5f40002f-8883-4bd2-8077-afb28ea15fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "# creating a token dictionary for word\n",
        "word_list = sum(sentences, [])\n",
        "word_list = sorted(set(word_list))\n",
        "word_list = ['<pad>'] + word_list\n",
        "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(len(idx2word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7J8Lfog6xrL",
        "outputId": "f41045a0-e078-472a-c23e-3dedf4e0db8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "# creating a token dictionary for part of speech\n",
        "pos_list = sum(pos, [])\n",
        "pos_list = sorted(set(pos_list))\n",
        "pos_list = ['<pad>'] + pos_list\n",
        "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos2idx)\n",
        "print(idx2pos)\n",
        "print(len(pos2idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPfwL4_J6xrO",
        "outputId": "334d6bcb-daaa-46ac-f21f-7f53e7389979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
        "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "# padding the sequence of indices\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
        "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
        "\n",
        "# checking data\n",
        "print(x_data, x_data_len)\n",
        "print(x_data_mask)\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpnpFwtM6xrV"
      },
      "source": [
        "### Creating model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bKHCGVga6xrX"
      },
      "outputs": [],
      "source": [
        "# creating bidirectional rnn for \"many to many\" sequence tagging\n",
        "num_classes = len(pos2idx)\n",
        "hidden_dim = 10\n",
        "\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)\n",
        "one_hot = np.eye(len(word2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(max_sequence,)))\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
        "                                 trainable=False, input_length=max_sequence,\n",
        "                                 embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "# layers.Birectional로만 변경\n",
        "model.add(layers.Bidirectional(keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)))\n",
        "\n",
        "# 토큰마다 품사 분류\n",
        "model.add(layers.TimeDistributed(keras.layers.Dense(units=num_classes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXoIXpY_6xra",
        "outputId": "797d35d9-3293-449b-b32a-eed8422889f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 15)            225       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 20)           520       \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 10, 8)            168       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913\n",
            "Trainable params: 688\n",
            "Non-trainable params: 225\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JviJxln76xrb"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OJdL2B6b6xrc"
      },
      "outputs": [],
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True) * masking    \n",
        "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
        "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
        "    return sequence_loss\n",
        "\n",
        "# creating and optimizer\n",
        "lr = 0.1\n",
        "epochs = 30\n",
        "batch_size = 2 \n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A81CsdDk6xrd",
        "outputId": "e89c4656-e3ee-47ad-f887-329e165210a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((None, 10), (None, 10), (None,)), types: (tf.int32, tf.int32, tf.int32)>\n"
          ]
        }
      ],
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
        "\n",
        "print(tr_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LEb30yq6xre",
        "outputId": "503f07c7-64f5-4d35-da6a-bd52b592ff8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.017\n",
            "epoch :  10, tr_loss : 0.001\n",
            "epoch :  15, tr_loss : 0.001\n",
            "epoch :  20, tr_loss : 0.000\n",
            "epoch :  25, tr_loss : 0.000\n",
            "epoch :  30, tr_loss : 0.000\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "    \n",
        "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables) # 가중치의 기울기 계산\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables)) # 경사 하강\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsKX78ng6xre"
      },
      "source": [
        "### Checking performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJvJyHt6xrf",
        "outputId": "6d1a7710-eab5-4746-8627-46ab7973a974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
        "\n",
        "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
        "pprint(pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Sm50DsqR6xrf",
        "outputId": "a3f5e50e-eeb6-428f-fa4c-853ff8193ff2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f007c812790>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(tr_loss_hist)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "[2.X코드반영] Lab 12-4: many to many bidirectional (simpled pos-tagger training, bidirectional).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}